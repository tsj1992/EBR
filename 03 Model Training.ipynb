{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ced907",
   "metadata": {},
   "source": [
    "# 03 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf412b93",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b2c0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import getsizeof\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe5d9e",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0982185",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './data'\n",
    "ORIGINAL_IMAGES = f'{BASE_PATH}/unsplit'\n",
    "IMAGE_PICKLES = f'{BASE_PATH}/pickles'\n",
    "IMAGE_NPYS = f'{BASE_PATH}/npys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f31c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CATEGORIES are  ['Black_Hooded_Oriole', 'Common_Myna', 'Indian_Peafowl', 'Intermediate_Egret', 'Other', 'Red_Faced_Malkoha', 'Rose_Ringed_Parakeet', 'White_Throated_Kingfisher']\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = os.listdir(ORIGINAL_IMAGES) # list the names of the categories that in my data\n",
    "print(str(len(CATEGORIES)),'CATEGORIES are ', CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca9e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image pickle save and load functions\n",
    "\n",
    "def save_pickle(obj, filename):\n",
    "    with open(os.path.join(IMAGE_PICKLES, f'{filename}.pkl'), 'wb') as f:  # open a text file\n",
    "        pickle.dump(obj, f) # serialize the list\n",
    "    \n",
    "def load_pickle(filename):\n",
    "    with open(os.path.join(IMAGE_PICKLES, f'{filename}.pkl'), 'rb') as f:\n",
    "        return pickle.load(f) # deserialize using load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ae469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_pickle('X_train')\n",
    "y_train = load_pickle('y_train')\n",
    "X_test = load_pickle('X_test')\n",
    "y_test = load_pickle('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8c2b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1900, 320, 400, 3), (1900,), (936, 320, 400, 3), (936,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c9b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 6, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34ce82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [6],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(len(y_train), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c031b3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(len(y_train), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f090ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(len(y_train), 1)\n",
    "y_test = y_test.reshape(len(y_test), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d1a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer that we will be used in out model i added batch normalization to accelerate the model and for generalization\n",
    "def conv_layer(inputs, filters, kernel_size=3, padding=\"valid\"):\n",
    "    x = layers.Conv2D(filters = filters, kernel_size = kernel_size, padding = padding, \n",
    "                      activity_regularizer=regularizers.L2(1e-4), use_bias = False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "# pooling layer i added dropout cause it help my model to reduce the overfitting\n",
    "def pooling_layer(inputs, pool_size = 2, dropout_rate=0.0):\n",
    "    x = layers.MaxPooling2D(pool_size = pool_size)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "# this dense layer i will not only use it for my base model i will use it in the pretrained model too\n",
    "def dense_layer(inputs, out, dropout_rate = 0.0):\n",
    "    x = layers.Dense(out, activity_regularizer=regularizers.L2(1e-5))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ff8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9947781",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (320, 400, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14455681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = conv_layer(inputs, 64, 3, padding = \"same\")  # 320 x 400\n",
    "x = conv_layer(x, 64, 3)                         # 318 x 398\n",
    "x = pooling_layer(x, 2)                          # 159 x 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6bd14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv_layer(x, 64, padding = \"same\")       # 159 x 199\n",
    "x = conv_layer(x, 64)                         # 157 x 197\n",
    "x = pooling_layer(x, 2)                       #  78 x  98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8b6c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv_layer(x, 64, padding = \"same\")       # 78 x 98\n",
    "x = conv_layer(x, 64)                         # 76 x 96\n",
    "x = pooling_layer(x, 2)                       # 38 x 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8eb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Flatten()(x)                       # 38*48*64 = 116,736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed71bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dense_layer(x, 512, dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d00661",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(len(CATEGORIES), \n",
    "                 activation = \"softmax\", \n",
    "                 activity_regularizer=regularizers.L2(1e-5))(x)\n",
    "outputs = layers.Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33df762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d2f2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 320, 400, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 320, 400, 64)      1728      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 320, 400, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 320, 400, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 318, 398, 64)      36864     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 318, 398, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 318, 398, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 159, 199, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 159, 199, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 159, 199, 64)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 159, 199, 64)      36864     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 159, 199, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 159, 199, 64)      0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 157, 197, 64)      36864     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 157, 197, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 157, 197, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 78, 98, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 78, 98, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 78, 98, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 78, 98, 64)        36864     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 78, 98, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 78, 98, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 76, 96, 64)        36864     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 76, 96, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 76, 96, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 38, 48, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 38, 48, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 38, 48, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 116736)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               59769344  \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59963848 (228.74 MB)\n",
      "Trainable params: 59961672 (228.74 MB)\n",
      "Non-trainable params: 2176 (8.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273bab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.compile(optimizer =keras.optimizers.Adam(learning_rate = 0.001),\n",
    "#                loss = 'categorical_crossentropy',\n",
    "#                metrics = ['accuracy'])\n",
    "\n",
    "base_model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001),\n",
    "               loss = 'sparse_categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0661f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fit model\n",
    "history = base_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs = 10, # adding more epochs will increase the acc like 1% or 2%\n",
    "    validation_split = 0.2,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df092a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label = \"Trianing accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b-\", label = \"Validation accuracy\")\n",
    "plt.title(\"Accuracy on training and validation data\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Trianing loss\")\n",
    "plt.plot(epochs, val_loss, \"b-\", label = \"Validation loss\")\n",
    "plt.title(\"loss on training and validation data\")\n",
    "plt.title(\"loss on training and validation data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model on the testset\n",
    "# test_model_base = keras.models.load_model(\"intial_model.keras\")\n",
    "_, test_acc = base_model.evaluate(test_generator)\n",
    "print(f\"The accuracy of the intial model on the test set is : {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f2a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
