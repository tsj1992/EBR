{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b334976",
   "metadata": {},
   "source": [
    "# 01 Image Preprocessing - PART 03 - PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df53a3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6e141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from sys import getsizeof\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d673053",
   "metadata": {},
   "source": [
    "### Mode of running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f7be0",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc4bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './data'\n",
    "ORIGINAL_IMAGES = f'{BASE_PATH}/unsplit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b93cad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CATEGORIES are  ['Black_Hooded_Oriole', 'Common_Myna', 'Indian_Peafowl', 'Intermediate_Egret', 'Other', 'Red_Faced_Malkoha', 'Rose_Ringed_Parakeet', 'White_Throated_Kingfisher']\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = os.listdir(ORIGINAL_IMAGES) # list the names of the categories that in my data\n",
    "print(str(len(CATEGORIES)),'CATEGORIES are ', CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fafd2d",
   "metadata": {},
   "source": [
    "### Reading the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "895e4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images():\n",
    "    dataset = []\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        cat_path = os.path.join(ORIGINAL_IMAGES, category)\n",
    "        cat_num = CATEGORIES.index(category)\n",
    "        for img_filename in os.listdir(cat_path):\n",
    "            img = cv2.imread(os.path.join(cat_path, img_filename))[...,::-1]  # read & convert from BGR to RGB\n",
    "            dataset.append([img, cat_num])\n",
    "        if TEST_MODE and cat_num == 2:\n",
    "            break # - then will only take the images from the first category\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0564945",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_images()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861ca2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(dataset[0][0][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c861a1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2834 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m itr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m itr\u001b[38;5;241m*\u001b[39mmem_err_avoid_batch_size\n\u001b[1;32m----> 4\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitr\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmem_err_avoid_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maug_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2953\u001b[0m, in \u001b[0;36mmin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2836\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[0;32m   2837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2838\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2839\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2840\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[0;32m   2841\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2951\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[0;32m   2952\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2954\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 2834 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "mem_err_avoid_batch_size = 100\n",
    "itr = 0\n",
    "start = itr*mem_err_avoid_batch_size\n",
    "end = np.min((itr+1)*mem_err_avoid_batch_size + 1, len(aug_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0714349",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_aug_dataset = []\n",
    "\n",
    "for aug_data in aug_dataset:\n",
    "    resized_aug_dataset.append(aug_data[0]/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782907fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_aug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(aug_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07963e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3495ad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(\u001b[43mtraining_data\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "random.shuffle(training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
