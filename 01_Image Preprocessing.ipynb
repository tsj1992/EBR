{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad86934",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6e141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37430cd1",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8b8f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'E:\\\\07_Workspaces\\\\01_Python\\\\03_ML\\\\EBR\\\\data'\n",
    "ORIGINAL_IMAGES = f'{BASE_PATH}\\\\unsplit'\n",
    "AUGMENTED_IMAGES = f'{ORIGINAL_IMAGES}\\\\aug'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fc1c4",
   "metadata": {},
   "source": [
    "### Image Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "09ca0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            rescale=1./255,\n",
    "                            shear_range=0.1,\n",
    "                            zoom_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b7f6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7044947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CATEGORIES are  ['Black_Hooded_Oriole', 'Common_Myna', 'Indian_Peafowl', 'Intermediate_Egret', 'Other', 'Red_Faced_Malkoha', 'Rose_Ringed_Parakeet', 'White_Throated_Kingfisher']\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = os.listdir(ORIGINAL_IMAGES) # list the names of the categories that in my data\n",
    "print(str(len(CATEGORIES)),'CATEGORIES are ', CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14331f57",
   "metadata": {},
   "source": [
    "### Preparing the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3e45adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for category in categories:\n",
    "    cat_path = os.path.join(ORIGINAL_IMAGES, category)\n",
    "    cat_num = CATEGORIES.index(category)\n",
    "    for img_filename in os.listdir(cat_path):\n",
    "        img = load_img(os.path.join(cat_path, img_filename))\n",
    "        dataset.append([img_to_array(img), cat_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f848bec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84d677fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = np.zeros((len(dataset),2))\n",
    "sizes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ede96",
   "metadata": {},
   "source": [
    "### Calculating the optimum size for image resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ae294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.zeros((len(dataset),2))\n",
    "for _idx, _data in enumerate(dataset):\n",
    "    sizes[_idx,:] = _data[0].shape[0], _data[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6adb6679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([569.00892857, 735.921875  ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6823ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([data for data in dataset if data[1] == ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
